# Non-continuous variables are defined for each FALSE (0) value in column "is_contin"
site <- fsite(row.names(is_contin)[is_contin$result == 0], Dat)
# Extract columns identified as non-continuous variables and put them into a new data frame 'discrete_Dat'
# If there are non-continuous variables, they will be put in a new data frame 'discrete_Dat'
if (length(site) > 0) {
# Extract columns identified as non-continuous variables and put them into a new data frame 'discrete_Dat'
discrete_Dat <- Dat[, site, drop = F]
}
# If there are no non-continuous variables, assign blank spaces to both variables 'discrete_fea_two' and 'discrete_fea_more'
if (length(site) == 0) {
discrete_fea_two <- discrete_fea_more <- ''
# Make a list consisting of variables 'contin_fea', 'discrete_fea_two', and 'discrete_fea_more' to show the Continuous Feature and Discrete Feature
result <- list(contin_fea,
discrete_fea_two,
discrete_fea_more)
# Name each element in the list
names(result) <- c('Contin_feature',
'Discrete_feature(level<=2)',
'Discrete_feature(level>2)')
# Return the result list
return(result)
}
# The str2() function is mainly used to separate discrete and multi-class variables.
str2 <- function(x){
# Convert the data frame into character, then remove the NA values
x <- na.omit(as.character(x))
# Convert all elements in x into factor, so we can treat unique values as levels
# Get all the unique levels of the factor, then count the number of unique levels
# Check if the length (amount) of unique levels is two or fewer
# If TRUE, return 1. If FALSE, return 0.
if(length(levels(factor(x))) <= 2)
{
return(1)
}
return(0)
}
# Apply function str2() to the columns of data frame discrete_Dat (parameter 1 means row, 2 means column)
# Then convert the output into a data frame and assign it to the is_two variable
is_two <- as.data.frame(apply(discrete_Dat, 2, function(x) str2(x)))
# Rename the is_two column to "result"
colnames(is_two) <- 'result'
# Use the fsite() function to find columns identified as discrete variables with 2 or fewer levels
site <- fsite(row.names(is_two)[is_two$result == 1], discrete_Dat)
# If there are discrete variables with 2 or fewer levels, they will be put in vector discrete_fea_two
ifelse(length(site) > 0,
# If there are discrete variables with 2 or fewer levels, assign their column names to discrete_fea_two
discrete_fea_two <- colnames(discrete_Dat)[site],
# If there are no discrete variables with 2 or fewer levels, assign an empty string to discrete_fea_two
discrete_fea_two <- '')
# Use the fsite() function to find columns identified as discrete variables with more than 2 levels
site <- fsite(row.names(is_two)[is_two$result == 0], discrete_Dat)
# If there are discrete variables with more than 2 levels, they will be put in vector discrete_fea_more
ifelse(length(site) > 0,
# If there are discrete variables with more than 2 levels, assign their column names to discrete_fea_more
discrete_fea_more <- colnames(discrete_Dat)[site],
# If there are no discrete variables with more than 2 levels, assign an empty string to discrete_fea_more
discrete_fea_more <- '')
# Put all the variables in the list and name them
# Return the list of continuous, discrete (level <= 2), and discrete (level > 2) features
result <- list(contin_fea,
discrete_fea_two,
discrete_fea_more)
names(result) <- c('Contin_feature',
'Discrete_feature(level<=2)',
'Discrete_feature(level>2)')
# The na_count() function is used to count the number of NA (missing) values for each row and column
# Define a function named na_count that takes a dataset 'Dat' and a boolean 'result' as arguments
na_count <- function(Dat,result = TRUE){
# Calculate and print the overall proportion of NA values in the entire dataset
message(paste0('NA ratio : ',sum(is.na(Dat))/(ncol(Dat)*nrow(Dat))))
# -----Count NA Values for Each Row-----
# Use function apply() to count the number of NA using function sum(is.na(x))
# margin=1 indicates that the function should be applied to rows
df_row <- apply(Dat,1,function(x){sum(is.na(x))})
# Convert the obtained data into data frame
df_row <- as.data.frame(df_row)
# Name the column as 'count', then convert it into numeric format
colnames(df_row) <- 'count'
df_row$count <- as.numeric(as.character(df_row$count))
# Calculate the proportion of missing values in each row to three decimal places
df_row$perc <- round((df_row$count)/ncol(Dat),3)
# Sort the data frame in descending order based on the number of NA values
df_row <- df_row[order(df_row$count,decreasing = TRUE),]
# -----Count NA Values for Each Column-----
# Use function apply() to count the number of NA using function sum(is.na(x))
# margin=2, then function count NA values for each column
df_col <- apply(Dat,2,function(x){sum(is.na(x))})
# Convert the obtained data into data frame
df_col <- as.data.frame(df_col)
# Name the column as 'count', then convert it into numeric format
colnames(df_col) <- 'count'
df_col$count <- as.numeric(as.character(df_col$count))
# Calculate the proportion of missing values in each column to three decimal places
df_col$perc <- round((df_col$count)/nrow(Dat),3)
# Sort the data frame in descending order based on the number of NA values
df_col <- df_col[order(df_col$count,decreasing = TRUE),]
# Make a list concsist of both NA values in each rows and columns data frames, then assinged into 'result_output' variable
result_output <- list(df_row,df_col)
# Give each of the list a name, then return the 'result_output' variable as function output
names(result_output) <- c('row','col')
return(result_output)
}
# Call the na_count() function to count the number of NA values in the dataset 'Dat'
# Count NA using the na_count() function, and stored in 'na_result' variable
na_result <- na_count(Dat)
# Merge both result from data types determination and NA amount counting in 'result' list
result <- list(contin_fea,
discrete_fea_two,
discrete_fea_more,
na_result)
# Name each element in the list
names(result) <- c('Contin_feature',
'Discrete_feature(level<=2)',
'Discrete_feature(level>2)',
'NA_count')
# The bat_as.change() function is used to convert the data types of the specified features in the dataset
bat_as.change <- function(name.v,Dat){
# Put input dataset into temporary variable
temp_df <- Dat
# Find features in input variable 'temp_df' that match the data from input 'name.v' variable
# The result is stored in 'site.v' variable using fsite() function
site.v <- fsite(name.v,
temp_df)
# Make a loop with number of iteration equal to length of 'site.v'
# If there's an index in site.name match with one element of 'site.v', convert it into numeric value
# Then the converted value is appended back to variable 'temp_df'
for(i in 1:length(site.v)){
temp_df[,site.v[i]] <- as.numeric(as.character(temp_df[,site.v[i]]))
}
return(temp_df)
}
# Extract the continuous variables from 'fea_result' variable
v.contin <- result$Contin_feature
new_df <- bat_as.change(v.contin,Dat)
# logic transformation for continuous variables
log_transform <- function(new_Dat, v.contin) {
transform_log <- function(x) {
# Try to apply log transformation and handle errors
tryCatch({
if (all(x > 0, na.rm = TRUE)) {
log(x)
} else {
# Adjust the values to be positive before applying log transformation
adjusted <- x - min(x, na.rm = TRUE) + 1e-6
log(adjusted)
}
}, error = function(e) {
warning(paste("Log transformation failed:", e$message))
x
})
}
for (col in v.contin) {
message(paste("Applying log transformation to column:", col))
new_col_name <- paste0("log_", col)
new_Dat[[new_col_name]] <- transform_log(new_Dat[[col]])
# Remove the new column if all values are NA
if (all(is.na(new_Dat[[new_col_name]]))) {
new_Dat[[new_col_name]] <- NULL
warning(paste("All values are NA in column:", new_col_name, "Column removed."))
}
# Check for infinite values and replace them with NA
if (any(is.infinite(new_Dat[[new_col_name]]))) {
new_Dat[[new_col_name]][is.infinite(new_Dat[[new_col_name]])] <- NA
warning(paste("Infinite values detected in column:", new_col_name, "Replaced with NA."))
}
}
return(new_Dat)
}
# Apply log transformation to continuous variables
if (length(v.contin) > 0) {
new_df <- log_transform(new_df, v.contin)
} else {
message("No continuous variables to apply log transformation.")
}
# Return the final result list containing continuous features, discrete features, and NA counts
return(new_df)
}
try <- data_process(test_data)
data <- data_process(test_data)
View(data)
#' # Extract the male vascular age
#' vascular_age <- try_result$age_pred$male$data$bioage
#'
#' # Extract the female vascular age
#' vascular_age <- try_result$age_pred$female$data$bioage
#'
#' # Extract the difference between vascular age and actual age
#' vascular_age_advanced <- try_result$age_pred$male$data$baaccel_diff
#'
#'
Vas_train <- function(Dat, v.name = c("MAP", "PWV", "ABI"), gender_col = "gender", male = "male", female = "female", split = 2, age_col = "age") {
# Check if the loaded data is a data frame
if (!inherits(Dat, "data.frame")) {
message("Input validation: Dat is not a data frame, attempting to convert to a data frame")
original_type <- class(Dat)[1]
tryCatch({
Dat <- as.data.frame(Dat)
message(paste("Successfully converted", original_type, "type to data frame"))
}, error = function(e) {
stop("Data type conversion failed:", e$message)
})
} else {
message("Input validation: Dat is already a data frame")
}
# Check if the loaded data has at least 10 rows
# If the number of rows is less than 10, print a warning message
if (nrow(Dat) < 10) {
warning("Small dataset warning: Sample size is less than 10, results may be unstable")
} else {
message("Input validation: Sample size is sufficient")
}
# Check the number of the specified biomarkers
# If the number of biomarkers is less than 2, stop the function and print a message
# If the number of biomarkers is greater than or equal to 2, print a message indicating that the number of biomarkers is valid
if (length(v.name) < 2) {
stop("The number of biomarkers must be at least 2.")
} else {
message("The number of biomarkers is valid.")
}
# Check for outliers in the specified biomarkers
for (var in v.name) {
quartiles <- quantile(Dat[[var]], probs = c(0.25, 0.75), na.rm = TRUE)
IQR <- IQR(Dat[[var]], na.rm = TRUE)
lower_bound <- quartiles[1] - 1.5 * IQR
upper_bound <- quartiles[2] + 1.5 * IQR
outliers <- Dat[[var]][Dat[[var]] < lower_bound | Dat[[var]] > upper_bound]
if (length(outliers) > 0) {
message(paste("Outlier check: The following outliers were found in", var, ":", paste(outliers, collapse = ", ")))
}
}
# Check if the loaded data has the required columns
required_columns <- c(v.name, gender_col, age_col)
# Check if the required_columns are present in the data frame
missing_columns <- setdiff(required_columns, colnames(Dat))
# If any required_columns are missing, stop the function and print the missing columns
# If all required_columns are present, print a message indicating that all required_columns are present
if (length(missing_columns) > 0) {
stop(paste("The following biomarkers are missing from the data frame:", paste(missing_columns, collapse = ", ")))
} else {
message("All required_columns are present in the data frame.")
}
# Validate that all biomarker columns are numeric
# If any biomarker columns are not numeric, stop the function and print a message
# If all biomarker columns are numeric, print a message indicating that the biomarker columns are valid
non_numeric_biomarkers <- v.name[!sapply(Dat[, v.name, drop = FALSE], is.numeric)]
if (length(non_numeric_biomarkers) > 0) {
stop("The following biomarkers are not numeric:", paste(non_numeric_biomarkers, collapse = ", "))
}
# Check if the specified biomarkers contain missing values
# If any missing values are found, stop the function and print a message
# If no missing values are found, print a message indicating that there are no missing values
na_report <- sapply(Dat[, v.name], function(x) {
na_count <- sum(is.na(x))
if(na_count > 0) paste(na_count, "missing values") else "no"
})
if (any(grepl("missing values", na_report))) {
message("Missing value check: The following biomarkers contain missing values:")
print(data.frame(Variable = names(na_report), Status = na_report))
stop("Please check the missing values in the specified biomarkers.")
} else {
message("Missing value check: No missing values in the specified biomarkers.")
}
# Enhanced gender classification validation
if (!is.factor(Dat[[gender_col]])) {
message("Gender column is not factor type, attempting to convert...")
tryCatch({
Dat[[gender_col]] <- as.factor(Dat[[gender_col]])
}, error = function(e) {
stop("Failed to convert gender column to factor: ", e$message)
})
}
gender_levels <- unique(Dat[[gender_col]])
if (!all(c(male, female) %in% gender_levels)) {
message("The detected gender categories in the data are -> ", paste(gender_levels, collapse = ", "))
}
if (length(gender_levels) > 2) {
message("Detected more than 2 gender categories: ", paste(gender_levels, collapse = ", "))
gender_counts <- table(Dat[[gender_col]])
print(gender_counts)
}
# Check if the age column is numeric and within a reasonable range (0-120)
if (!is.numeric(Dat[[age_col]])) {
message("Age column is not numeric, attempting to convert...")
tryCatch({
Dat[[age_col]] <- as.numeric(Dat[[age_col]])
}, error = function(e) {
stop("Failed to convert age column to numeric: ", e$message)
})
}
age_values <- Dat[[age_col]]
if (any(age_values < 0 | age_values > 120)) {
invalid_ages <- age_values[age_values < 0 | age_values > 120]
message("The number of abnormal age values: ", length(invalid_ages))
message("The abnormal age values are: ", paste(invalid_ages, collapse = ", "))
warning("Unusual age values detected (<0 or >120). Please check data quality.")
}
# Check if split is numeric 1， 2, or 3
if (!is.numeric(split)) {
stop("split must be numeric")
}
if (split %% 1 != 0) {
split <- as.integer(split)
message("split is not an integer, converting to integer")
}
if (!split %in% 1:3) {
stop("split must be 1, 2, or 3")
}
# The split parameter is automatically adjusted based on the number of gender factors
if (length(gender_levels) == 1){
split <- 2
message("Gender has only one level; Only one level result is output")
}
# The auto_std() function is used to standardize the data
auto_std <- function(Dat, v.name, gender_col, male, female, split){
# Initialize an empty list to store standardization tables for each gender
tab_std_list <- list()
standardized_data <- list()
# Calculate the standardization parameters (mean and standard deviation) for each variable in v.name
# The calc_std_params() function is used to calculate the mean and standard deviation of the specified variables
# The function takes a data frame and a vector of variable names as input and returns a data frame with the mean and standard deviation for each variable
calc_std_params <- function(data_subset, v.name) {
params <- data.frame(
term = v.name,
u = sapply(data_subset[, v.name], mean, na.rm = TRUE),
sd = sapply(data_subset[, v.name], sd, na.rm = TRUE)
)
return(params)
}
# The apply_standardization() function is used to standardize the data using the mean and standard deviation
# The function takes a data frame and a data frame of standardization parameters as input and returns the standardized data frame
# The function loops through each variable name in the standardization parameters and applies the standardization formula
# If the standard deviation is not equal to 0, standardize the data by subtracting the mean and dividing by the standard deviation
# If the standard deviation is equal to 0, standardize the data by subtracting the mean only
# The function returns the standardized data frame
apply_standardization <- function(data_subset, params) {
for (i in seq_along(params$term)) {
term <- params$term[i]
u <- params$u[i]
sd_val <- params$sd[i]
if (sd_val != 0) {
data_subset[, term] <- (data_subset[, term] - u) / sd_val
} else {
data_subset[, term] <- data_subset[, term] - u
}
}
return(data_subset)
}
# Check if the split is 1 or 3, all data is used for standardization
if (split %in% c(1, 3)) {
# Standardize the data using all data
Dat_all <- Dat
# Using the calc_std_params() function to calculate the mean and standard deviation of the specified variables
tab_std_all <- calc_std_params(Dat, v.name)
# Using the apply_standardization() function to standardize the data using the mean and standard deviation
Dat_all <- apply_standardization(Dat_all, tab_std_all)
# Store the standardization parameters and standardized data in the list
tab_std_list$all <- tab_std_all
standardized_data$all <- Dat_all
}
# Check if the split is 2 or 3, feamle and male data are used for standardization
if (split %in% c(2, 3)){
# Check if there is male data in the gender column
if (any(Dat[, gender_col] == male)) {
# Standardize the male data
Dat_male <- Dat[Dat[[gender_col]] == male, ]
# Using the calc_std_params() function to calculate the mean and standard deviation of the specified variables
tab_std_male <- calc_std_params(Dat_male, v.name)
# Using the apply_standardization() function to standardize the data using the mean and standard deviation
Dat_male <- apply_standardization(Dat_male, tab_std_male)
# Store the standardization parameters and standardized data in the list
tab_std_list$male <- tab_std_male
} else {
Dat_male <- NULL
tab_std_list$male <- NULL
}
# Check if there is female data in the gender column
if (any(Dat[, gender_col] == female)) {
Dat_female <- Dat[Dat[,gender_col] == female, ]
# Using the calc_std_params() function to calculate the mean and standard deviation of the specified variables
# Using the apply_standardization() function to standardize the data using the mean and standard deviation
tab_std_female <- calc_std_params(Dat_female, v.name)
Dat_female <- apply_standardization(Dat_female, tab_std_female)
# Store the standardization parameters and standardized data in the list
tab_std_list$female <- tab_std_female
} else {
Dat_female <- NULL
tab_std_list$female <- NULL
}
# Rbind the data
if (!is.null(Dat_male) && !is.null(Dat_female)) {
standardized_data$gender <- rbind(Dat_male, Dat_female)
} else if (!is.null(Dat_male)) {
standardized_data$gender <- Dat_male
} else if (!is.null(Dat_female)) {
standardized_data$gender <- Dat_female
}
}
# Return the standardization tables and the processed data frame
return(list(params = tab_std_list, Data = standardized_data))
}
# The 'run_pca()' function is used to perform PCA analysis on the data
run_pca <- function(data, gender_col, age_col, v.name_pc) {
# Check if the data frame is empty, and if so, print a message and return NULL
if (is.null(data) || nrow(data) == 0) {
message("The data frame is empty. PCA cannot be performed.")
return(NULL)
}
# The specification of the PCA analysis is as follows:
# center=F -> the data is not centered, centered by subtracting with the mean
# scale=F -> the data is not scaled (usually, scaled by dividing with the standard deviation)
# The PCA analysis is performed on the specified variables in v.name
pca <- prcomp(data[, v.name], center = FALSE, scale = FALSE)
# Calculate the standard deviation of the principal components and divide it by the sum of the standard deviations. This will give the proportion of variance explained by each principal component.
# The eigenvector is the rotation matrix of the principal components
pca$sdev/sum(pca$sdev)
eigenvector <- pca$rotation
# Calculate the loadings of the principal components
# The loadings are the eigenvectors multiplied by the standard deviations and stored in the 'rawLoadings' variable
rawLoadings <- pca$rotation[,1:ncomp] %*% diag(pca$sdev, ncomp, ncomp)
# The original loadings are rotated using the varimax() function to obtain simpler and more interpretable factor loadings
# The varimax() function returns the rotated loading matrix, which can be extracted through $loadings.
rotatedLoadings <- varimax(rawLoadings)$loadings
# Convert the principal components of the training set to a data frame
dat_pca <- as.data.frame(pca$x)
# Merge the 'Age' column from the 'data_std_train' data frame to the 'dat_pca' data frame
dat_pca <- cbind(dat_pca, data[, c(gender_col, age_col)])
# Construct the bioage model using the principal components
# The 'bioage::kdm_calc()' function is used to calculate the bioage model using the principal components
# The function takes the data frame, age variable, and biomarker names as input and returns the bioage model
# The function returns the bioage model
model <- bioage::kdm_calc(dat_pca, agevar = age_col, biomarkers = v.name_pc)
age_pred <- bioage::kdm_calc(dat_pca, agevar = age_col, biomarkers = v.name_pc,fit = model$fit)
# Return the PCA results and the bioage model
return(list(pca = pca, model = model, eigenvector = eigenvector,dat_pca = dat_pca, age_pred = age_pred))
}
# Call the auto_std() function to standardize the data
list_std <- auto_std(Dat, v.name, gender_col, male, female, split)
# df_std is the standardization parameters
df_std <- list_std[[1]]
# The standardized train set is stored in the 'data_std_train' variable
data_std_train <- list_std[[2]]
# The number of components used in the basic model is equal to the number of basic model indicators
ncomp <- length(v.name)
# v.name_pc is the name of the principal components in the model and is stored in the 'v.name_pc' variable
v.name_pc <- paste0("PC",c(1:length(v.name)))
# Extract the basic model indicators from the standardized training sets
train_model <- list()
eigenvector <- list()
age_pred <- list()
eta <- list()
# Train a combined model using all participants when split is 1 or 3
if (split %in% c(1, 3)) {
# Extract the standardized training dataset containing all participants
t.train <- data_std_train$all
# Select relevant columns: gender, age, and feature variables for model training
# These indicators will be used to build the baseline model
t.train_all <- t.train[,c(gender_col, age_col, v.name)]
# Run Principal Component Analysis (PCA) on the combined dataset
train_model$all <- run_pca(t.train_all, gender_col, age_col, v.name_pc)
# Extract eigenvectors (principal component directions) from the trained model
eigenvector$all <- train_model$all$eigenvector
# Extract age prediction results from the trained model
age_pred$all <- train_model$all$age_pred
# Calculate eta effect size: (actual age variance - brain age error variance) / actual age variance
# Higher eta values indicate better model performance
eta$all <- (age_pred$all$data$agevar - age_pred$all$data$ba.e) / age_pred$all$data$agevar
}
# Train separate gender-specific models when split is 2 or 3
if (split %in% c(2, 3)) {
# Extract the gender-stratified standardized training dataset
t.train <- data_std_train$gender
# Select relevant columns: gender, age, and feature variables
t.train <- t.train[,c(gender_col, age_col, v.name)]
# Split the dataset by gender to create male and female subsets
t.train_male <- t.train[t.train[,gender_col] == male, ]
t.train_female <- t.train[t.train[,gender_col] == female, ]
# Train model for male participants if male data is available
if (nrow(t.train_male) > 0) {
# Run PCA analysis on male-only dataset
train_model$male <- run_pca(t.train_male, gender_col, age_col, v.name_pc)
# Extract eigenvectors from the male-specific model
eigenvector$male <- train_model$male$eigenvector
# Extract age prediction results from the male-specific model
age_pred$male <- train_model$male$age_pred
# Calculate eta effect size for the male-specific model
eta$male <- (age_pred$male$data$agevar - age_pred$male$data$ba.e) / age_pred$male$data$agevar
}
# Train model for female participants if female data is available
if (nrow(t.train_female) > 0) {
# Run PCA analysis on female-only dataset
train_model$female <- run_pca(t.train_female, gender_col, age_col, v.name_pc)
# Extract eigenvectors from the female-specific model
eigenvector$female <- train_model$female$eigenvector
# Extract age prediction results from the female-specific model
age_pred$female <- train_model$female$age_pred
# Calculate eta effect size for the female-specific model
eta$female <- (age_pred$female$data$agevar - age_pred$female$data$ba.e) / age_pred$female$data$agevar
}
}
# Return a comprehensive list containing all trained models and related data structures
# train_std: standardized training data used for model development
# train_model: trained PCA models (all/male/female specific models)
# data_std_train: standardized training datasets organized by group
# eigenvector: principal component directions/loadings for each trained model
# age_pred: age prediction results and performance metrics for each model
# eta: effect size measurements for evaluating model prediction accuracy
return(list(train_std = df_std, train_model = train_model, data_std_train = data_std_train, eigenvector = eigenvector, age_pred = age_pred, eta = eta))
}
result <- Vas_train(data)
View(result)
head(result$age_pred$female$data$bioage)
result$age_pred$female$data$bioage
